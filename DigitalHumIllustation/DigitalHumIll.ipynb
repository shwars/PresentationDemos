{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT как персональный раб разработчика\n",
    "\n",
    "Используем большие языковые модели для автоматизации сложных задач.\n",
    "\n",
    "Для начала научимся использовать большие языковые модели программно. Я рекомендую посмотреть на библиотеку [LangChain](https://www.langchain.com/), или её клон от Сбера - [GigaChain](https://github.com/ai-forever/gigachain).\n",
    "\n",
    "Для поддержки модели Yandex GPT можно дополнительно установить библиотеку [`yandex_chain`](https://github.com/yandex-datasphere/yandex-chain). В GigaChat уже присутствует поддержка языковых моделей Yandex.\n",
    "\n",
    "Вот как просто можно организовать вызов языковой модели Yandex GPT из кода:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Жил-был мальчик по имени Иван. Он был очень любознательным и любил узнавать что-то новое. Однажды он услышал о JSON и решил узнать о нем больше.\n",
      "\n",
      "Он начал читать книги и статьи о JSON и узнал, что это язык разметки данных, который используется для передачи данных между различными программами и сервисами. Иван был очень заинтересован и решил попробовать использовать JSON в своей жизни.\n",
      "\n",
      "Он начал создавать свои собственные JSON-файлы, которые содержали информацию о его увлечениях, интересах и достижениях. Он также начал использовать JSON для передачи данных между различными программами и сервисами, такими как веб-сайты и приложения.\n",
      "\n",
      "Иван продолжал изучать JSON и применять его в своей жизни. Он стал более уверенным в своих знаниях и начал делиться своими знаниями с другими. Он также стал более успешным в своей работе и учебе благодаря своим знаниям о JSON.\n",
      "\n",
      "В конце концов, Иван стал экспертом в области JSON и использовал его для решения различных задач в своей жизни. Он стал известным специалистом в своей области и получил множество наград и премий за свои достижения.\n",
      "\n",
      "Так Иван стал тем мальчиком, который любил JSON и использовал его для достижения своих целей.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import YandexGPT, GigaChat\n",
    "import json\n",
    "\n",
    "config = json.load(open('config.json'))\n",
    "\n",
    "GPT = YandexGPT(api_key = config['api_key'], temperature=0.01)\n",
    "GC = GigaChat(credentials=config['gigachain_auth'],verify_ssl_certs=False)\n",
    "\n",
    "print(GPT(\"Напиши сказку про мальчика, который любил JSON\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New pypi version: 0.1.9.0 (current: 0.1.8.1) | pip install -U g4f\n"
     ]
    }
   ],
   "source": [
    "import g4f \n",
    "\n",
    "def GPT4(x):\n",
    "    response = g4f.ChatCompletion.create(\n",
    "    model=g4f.models.default,\n",
    "    messages=[{\"role\": \"user\", \"content\": x }])\n",
    "    return response\n",
    "\n",
    "res = GPT4('Придумай сказку про мальчика, который любил JSON')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Используем условия\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Инструкций нет\n"
     ]
    }
   ],
   "source": [
    "text1 = \"\"\"\n",
    "Чтобы приготовить омлет, сначала надо взять яйца. Разбиваем их молотком, затем\n",
    "аккуратно извлекаем осколки скорлупы. Затем добавляем соли. В конце кладем масло на\n",
    "сковородку, и выливаем туда яичную смесь.\n",
    "\"\"\"\n",
    "\n",
    "text2 = \"\"\"\n",
    "Яичный омлет - это прекрасный завтрак! Вам обязательно стоит его попробовать, если\n",
    "раньше никогда не пробовали!\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    Тебе будет дан текст, выделенный тройными обратными кавычками. Если\n",
    "    в тексте содержится последовательность инструкций, перепиши их\n",
    "    в виде последовательных шагов в таком формате:\n",
    "    Шаг 1 - ...\n",
    "    Шаг 2 - ...\n",
    "    ...\n",
    "    Шаг N - ...\n",
    "\n",
    "    Если в тексте нет конкретных инструкций, напиши \"Инструкций нет\". \n",
    "    ```{text}```\"\"\",\n",
    "    input_variables=[\"text\"],\n",
    ")\n",
    "\n",
    "res = GPT(prompt.format(text=text2))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дайте модели время подумать!\n",
    "\n",
    "Языковые модели не могут рассуждать, как человек, гоняя мысли в голове \"взад-вперёд\". Модель всегда генерирует текст \"вперёд\", и \"рассуждает\" в процессе генерации. Поэтому важно инструктировать модель так, чтобы она могла \"рассуждать вслух\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Использовать генеративный ИИ полезно, потому что это очень сильно ускоряет работу.\", \"Работать с ChatGPT, мы можем многому у него научиться.\", \"Используя передовые технологии, мы будем современными и не отставать от прогресса.\", \"Есть риск, что мы при этом разучимся сами писать.\"]\n",
      "\n",
      "[\"позитивно\", \"позитивно\", \"позитивно\", \"негативно\"]\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Использовать генеративный ИИ полезно, потому что это очень \n",
    "сильно ускоряет работу. Также, работая с ChatGPT, мы можем\n",
    "многому у него научиться. Используя передовые технологии,\n",
    "мы будем современными и не отставать от прогресса. Но есть риск,\n",
    "что мы при этом разучимся сами писать.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    Тебе нужно сделать следующее:\n",
    "    1. Выдели умные мысли, которые содержатся в тексте ниже, \n",
    "    выделенном тройными обратными кавычками.\n",
    "    2. Построй список из всех умных мыслей\n",
    "    2. Для каждой умной мысли определи, является ли она позитивной\n",
    "    или негативной.\n",
    "    3. Выведи ответ в формате JSON, который содержит список\n",
    "    умных мыслей и их позитивность/негативность.\n",
    "    ```{text}```\"\"\",\n",
    "    input_variables=[\"text\"],\n",
    ")\n",
    "\n",
    "res = GPT(prompt.format(text=text))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Умные мысли:\n",
      "- Использовать генеративный ИИ полезно, потому что это очень сильно ускоряет работу.\n",
      "- Работать с ChatGPT, мы можем многому у него научиться.\n",
      "- Есть риск, что мы при этом разучимся сами писать.\n",
      "- Используя передовые технологии, мы будем современными и не отставать от прогресса.\n",
      "\n",
      "Позитивные мысли:\n",
      "- Использовать генеративный ИИ полезно, потому что это очень сильно ускоряет работу.\n",
      "- Работать с ChatGPT, мы можем многому у него научиться.\n",
      "\n",
      "Негативные мысли:\n",
      "- Есть риск, что мы при этом разучимся сами писать.\n",
      "\n",
      "Ответ:\n",
      "{\n",
      "  \"умные мысли\": [\n",
      "    \"Использовать генеративный ИИ полезно, потому что это очень сильно ускоряет работу.\",\n",
      "    \"Работать с ChatGPT, мы можем многому у него научиться.\",\n",
      "    \"Есть риск, что мы при этом разучимся сами писать.\",\n",
      "    \"Используя передовые технологии, мы будем современными и не отставать от прогресса.\"\n",
      "  ],\n",
      "  \"позитивные мысли\": [\n",
      "    \"Использовать генеративный ИИ полезно, потому что это очень сильно ускоряет работу.\",\n",
      "    \"Работать с ChatGPT, мы можем многому у него научиться.\"\n",
      "  ],\n",
      "  \"негативные мысли\": [\n",
      "    \"Есть риск, что мы при этом разучимся сами писать.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Использовать генеративный ИИ полезно, потому что это очень \n",
    "сильно ускоряет работу. Также, работая с ChatGPT, мы можем\n",
    "многому у него научиться. Но есть риск,\n",
    "что мы при этом разучимся сами писать. Используя передовые технологии,\n",
    "мы будем современными и не отставать от прогресса. \n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    Тебе нужно сделать следующее:\n",
    "    1. Выдели умные мысли, которые содержатся в тексте ниже, \n",
    "    выделенном тройными обратными кавычками.\n",
    "    2. Построй список из всех умных мыслей\n",
    "    2. Для каждой умной мысли определи, является ли она позитивной\n",
    "    или негативной.\n",
    "    3. Выведи ответ в формате JSON, который содержит список\n",
    "    умных мыслей и их позитивность/негативность.\n",
    "    Используй следующий формат:\n",
    "    Текст: <исходный текст с мыслями>\n",
    "    Умные мысли: <список умных мыслей>\n",
    "    Позитивные мысли: <список позитивных мыслей>\n",
    "    Негативные мысли: <список негативных мыслей>\n",
    "    \n",
    "    Вот текст, с которым тебе надо работать:\n",
    "    ```{text}```\"\"\",\n",
    "    input_variables=[\"text\"],\n",
    ")\n",
    "\n",
    "GPT.temperature=0.01\n",
    "res = GPT(prompt.format(text=text))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверка решения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Решение студента верное. Он правильно вычислил стоимость каждой из составляющих уборки и затем сложил их, чтобы получить общую стоимость уборки. Ответ студента - 2800 рублей - верен.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Тебе необходимо проверить решение задачи по математике студентом. Напиши, правильное\n",
    "ли решение студента или нет.\n",
    "\n",
    "Задача:\n",
    "Необходимо посчитать стоимость уборки в доме площадью 20 кв.метров. \n",
    "Стоимость уборки складывается из:\n",
    "- приезд уборщика - 200 руб.\n",
    "- мытьё полов - 100 руб. за кв. метр.\n",
    "- уборка кухни - 500 руб.\n",
    "- чистка полов - 50 руб. за кв. метр.\n",
    "\n",
    "Решение студента:\n",
    "{solution}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"solution\"],\n",
    ")\n",
    "\n",
    "correct = \"\"\"\n",
    "Стоимость уборки:\n",
    "- приезд уборщика - 200 руб.\n",
    "- мытьё полов - 100 руб. * 20 кв. метров = 2000 руб.\n",
    "- уборка кухни - 500 руб.\n",
    "- чистка полов - 50 руб. * 20 кв. метров = 1000 руб.\n",
    "Общая стоимость: 200 руб. + 2000 руб. + 500 руб. + 1000 руб. = 3700 руб.\n",
    "Ответ: 3700 руб.\n",
    "\"\"\"\n",
    "\n",
    "incorrect = \"\"\"\n",
    "Стоимость уборки:\n",
    "- приезд уборщика - 200 руб.\n",
    "- мытьё полов - 100 руб. * 20 кв. метров = 2000 руб.\n",
    "- уборка кухни - 500 руб.\n",
    "- чистка полов - 5 руб. * 20 кв. метров = 100 руб.\n",
    "Общая стоимость: 200 руб. + 2000 руб. + 500 руб. + 100 руб. = 2800 руб.\n",
    "Ответ: 2800 руб.\n",
    "\"\"\"\n",
    "\n",
    "print(GPT4(prompt.format(solution=incorrect)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Хорошо, посчитаем стоимость уборки в доме площадью 20 квадратных метров.\n",
      "\n",
      "1. Приезд уборщика: 200 руб.\n",
      "\n",
      "2. Мытье полов: 100 руб. × 20 кв. метров = 2000 руб.\n",
      "\n",
      "3. Уборка кухни: 500 руб.\n",
      "\n",
      "4. Чистка полов: 50 руб. × 20 кв. метров = 1000 руб.\n",
      "\n",
      "Теперь сложим все стоимости:\n",
      "\n",
      "200 руб. + 2000 руб. + 500 руб. + 1000 руб. = 3700 руб.\n",
      "\n",
      "Таким образом, стоимость уборки в доме площадью 20 квадратных метров составляет 3700 рублей.\n"
     ]
    }
   ],
   "source": [
    "res = GPT4(\"\"\"\n",
    "Пожалуйста, реши по шагам следующую задачу:\n",
    "Необходимо посчитать стоимость уборки в доме площадью 20 кв.метров. \n",
    "Стоимость уборки складывается из:\n",
    "- приезд уборщика - 200 руб.\n",
    "- мытьё полов - 100 руб. за кв. метр.\n",
    "- уборка кухни - 500 руб.\n",
    "- чистка полов - 50 руб. за кв. метр.\n",
    "\"\"\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Давайте разберемся с этой задачей пошагово:\n",
      "\n",
      "1. Приезд уборщика - 200 руб.\n",
      "2. Мытье полов - 100 руб. * 20 кв. метров = 2000 руб.\n",
      "3. Уборка кухни - 500 руб.\n",
      "4. Чистка полов - 50 руб. * 20 кв. метров = 1000 руб.\n",
      "\n",
      "Теперь сложим все эти стоимости вместе:\n",
      "\n",
      "200 руб. (приезд уборщика) + 2000 руб. (мытье полов) + 500 руб. (уборка кухни) + 1000 руб. (чистка полов) = 3700 руб.\n",
      "\n",
      "Ответ: стоимость уборки дома площадью 20 кв. метров составляет 3700 рублей.\n",
      "\n",
      "Теперь сравним мое решение с решением студента:\n",
      "\n",
      "Решение студента:\n",
      "- Приезд уборщика - 200 руб.\n",
      "- Мытье полов - 100 руб. * 20 кв. метров = 2000 руб.\n",
      "- Уборка кухни - 500 руб.\n",
      "- Чистка полов - 5 руб. * 20 кв. метров = 100 руб.\n",
      "Общая стоимость: 200 руб. + 2000 руб. + 500 руб. + 100 руб. = 2800 руб.\n",
      "\n",
      "Решение студента содержит ошибку в расчете чистки полов. Он посчитал 5 рублей за квадратный метр, вместо 50 рублей, как указано в условии задачи. Поэтому студент неправильно рассчитал общую стоимость уборки и получил 2800 рублей вместо правильных 3700 рублей.\n",
      "\n",
      "Итак, решение студента неверное из-за ошибки в расчете чистки полов.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Тебе необходимо проверить решение задачи по математике студентом, которое приведено\n",
    "ниже в тройных обратных кавычках. Напиши, правильное\n",
    "ли решение студента или нет. Тебе необходимо сделать следующее:\n",
    "1. Сначала, реши задачу самостоятельно и выведи пошаговое решение.\n",
    "2. Сравни решение студента с твоим решением и скажи, правильно ли\n",
    "решение студента.\n",
    "Не принимай решения о том, правильно ли студент решил задачу, пока не \n",
    "решишь её самостоятельно.\n",
    "В качестве ответа представь своё решение и напиши, правильно ли студент\n",
    "решил задачу, и где он ошибся.\n",
    "\n",
    "Задача:\n",
    "Необходимо посчитать стоимость уборки в доме площадью 20 кв.метров. \n",
    "Стоимость уборки складывается из:\n",
    "- приезд уборщика - 200 руб.\n",
    "- мытьё полов - 100 руб. за кв. метр.\n",
    "- уборка кухни - 500 руб.\n",
    "- чистка полов - 50 руб. за кв. метр.\n",
    "\n",
    "Решение студента:\n",
    "```{solution}```\n",
    "Напоминаю, что тебе нужно самой решить задачу, и потом сравнить своё решение с решением студента.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"solution\"],\n",
    ")\n",
    "\n",
    "correct = \"\"\"\n",
    "Стоимость уборки:\n",
    "- приезд уборщика - 200 руб.\n",
    "- мытьё полов - 100 руб. * 20 кв. метров = 2000 руб.\n",
    "- уборка кухни - 500 руб.\n",
    "- чистка полов - 50 руб. * 20 кв. метров = 1000 руб.\n",
    "Общая стоимость: 200 руб. + 2000 руб. + 500 руб. + 1000 руб. = 3700 руб.\n",
    "Ответ: 3700 руб.\n",
    "\"\"\"\n",
    "\n",
    "incorrect = \"\"\"\n",
    "Стоимость уборки:\n",
    "- приезд уборщика - 200 руб.\n",
    "- мытьё полов - 100 руб. * 20 кв. метров = 2000 руб.\n",
    "- уборка кухни - 500 руб.\n",
    "- чистка полов - 5 руб. * 20 кв. метров = 100 руб.\n",
    "Общая стоимость: 200 руб. + 2000 руб. + 500 руб. + 100 руб. = 2800 руб.\n",
    "Ответ: 2800 руб.\n",
    "\"\"\"\n",
    "\n",
    "print(GPT4(prompt.format(solution=incorrect)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основные приёмы использования \n",
    "\n",
    "1. Генерация текста по данным (экспансия)\n",
    "2. Извлечение данных из текста (экстракция)\n",
    "3. Суммаризация текста\n",
    "4. Десуммаризация текста\n",
    "5. Переписывание текста (тональность, акцент)\n",
    "6. Преобразование текста (перевод)\n",
    "\n",
    "### Пример\n",
    "\n",
    "Рассмотрим пример суммаризации множества отзывов, чтобы можно было охватить их одним взглядом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отзыв о Макдональдсе: быстрое обслуживание, но невкусная еда.\n",
      "\"Макдональдс - это прекрасное место, где можно поесть американскую еду: гамбургеры, картошку фри и конечно же прекрасное мороженое! Я обычно заказываю биг мак, в котором много вкусного зелёного салата. Это делает еду полезной и здоровой, что очень хорошо! Спасибо всем официантам, которые всегда улыбаются и радуются мне!\"\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "reviews = [\"\"\"\n",
    "Я посетил ресторан Макдональдс летом прошлого года, и был разочарован!\n",
    "Из позитивных моментов: обслуживание было быстрым, я получил заказ через 5 минут.\n",
    "Но при этом весь персонал был мрачным, и еда оказалась не очень вкусной. Картошка\n",
    "была сырая и пахла резиной, а мясо в гамбургере было серым на цвет.\n",
    "\"\"\",\"\"\"\n",
    "Макдональдс - это прекрасное место, где можно поесть американскую еду:\n",
    "гамбургеры, картошку фри и конечно же прекрасное мороженое!\n",
    "Я обычно заказываю биг мак, в котором много вкусного зелёного салата.\n",
    "Это делает еду полезной и здоровой, что очень хорошо! Спасибо всем официантам,\n",
    "которые всегда улыбаются и радуются мне!\n",
    "\"\"\"]\n",
    "\n",
    "template = \"\"\"\"\n",
    "Ниже в тройных обратных кавычках приводится отзыв посетитея о ресторане. Пожалуйста,\n",
    "перефразируй отзыв коротко в одном предложении:\n",
    "```{review}```\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"review\"],\n",
    ")\n",
    "\n",
    "GPT.temperature = 0.01\n",
    "for r in reviews:\n",
    "    res = GPT(prompt.format(review=r))\n",
    "    print(res)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно также сконцентрировать отзывы на каком-то одном интересующем нас аспекте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отзыв о посещении McDonald's: разочаровывающий опыт с невкусной едой.\n",
      "\"В Макдональдсе подают вкусную и здоровую американскую еду, включая гамбургеры, картошку фри и мороженое. Я обычно заказываю Биг Мак с большим количеством салата, что делает его полезным. Официанты всегда дружелюбны и рады видеть меня.\"\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\"\n",
    "Ниже в тройных обратных кавычках приводится отзыв посетитея о ресторане. Пожалуйста,\n",
    "перефразируй отзыв коротко в одном предложении, обратив внимание исключительно на\n",
    "качество еды:\n",
    "```{review}```\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"review\"],\n",
    ")\n",
    "\n",
    "GPT.temperature = 0.01\n",
    "for r in reviews:\n",
    "    res = GPT(prompt.format(review=r))\n",
    "    print(res)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А если на нужен более подробный анализ отзывов - мы можем прибегнуть к извлечению данных в формате JSON, для последующего анализа:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"обслуживание\": \"обслуживание было быстрым\",\n",
      "  \"еда\": \"картошка была сырая и пахла резиной, мясо в гамбургере было серым на цвет\",\n",
      "  \"тональность\": \"разочарован\"\n",
      "}\n",
      "{\n",
      "  \"обслуживание\": \"Я обычно заказываю биг мак, в котором много вкусного зелёного салата.\",\n",
      "  \"еда\": \"гамбургеры, картошку фри\",\n",
      "  \"тональность\": \"положительный\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "template = '''\n",
    "Ниже в тройных обратных кавычках приводится отзыв посетитея о ресторане. Пожалуйста,\n",
    "прочитай этот отзыв, и извлеки из него следующую информацию:\n",
    "1. Качество обслуживания\n",
    "2. Качесвто еды\n",
    "3. Общая тональность отзыва: положительный или отрицательный.\n",
    "Результат верни в формате JSON такого вида:\n",
    "{{\n",
    "  \"обслуживание\" : \"...\",\n",
    "  \"еда\" : \"...\",\n",
    "  \"тональность\" : \"...\"\n",
    "}}\n",
    "Вот сам отзыв:\n",
    "```{review}```\n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"review\"],\n",
    ")\n",
    "\n",
    "GPT.temperature = 0.5\n",
    "for r in reviews:\n",
    "    res = GPT(prompt.format(review=r))\n",
    "    print(res)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для более точного парсинга стоит использовать `JsonOutputParser`. Заодно попросим извлечь побольше разной информации в одном запросе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'обслуживание': 3, 'еда': 1, 'тональность': -1, 'саммари': 'Плохое обслуживание и невкусная еда', 'англ': 'The service was bad and the food was not tasty.'}\n",
      "{'обслуживание': 5, 'еда': 4, 'тональность': 1, 'саммари': 'Отличное обслуживание и вкусная еда', 'англ': \"McDonald's is a great place to eat American food: hamburgers, fries and, of course, great ice cream!\"}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>обслуживание</th>\n",
       "      <th>еда</th>\n",
       "      <th>тональность</th>\n",
       "      <th>саммари</th>\n",
       "      <th>англ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Плохое обслуживание и невкусная еда</td>\n",
       "      <td>The service was bad and the food was not tasty.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Отличное обслуживание и вкусная еда</td>\n",
       "      <td>McDonald's is a great place to eat American fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   обслуживание  еда  тональность                              саммари  \\\n",
       "0             3    1           -1  Плохое обслуживание и невкусная еда   \n",
       "1             5    4            1  Отличное обслуживание и вкусная еда   \n",
       "\n",
       "                                                англ  \n",
       "0    The service was bad and the food was not tasty.  \n",
       "1  McDonald's is a great place to eat American fo...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "\n",
    "parser = SimpleJsonOutputParser()\n",
    "\n",
    "template = '''\n",
    "Ниже в тройных обратных кавычках приводится отзыв посетитея о ресторане. Пожалуйста,\n",
    "прочитай этот отзыв, и извлеки из него следующую информацию:\n",
    "1. Качество обслуживания (оцени в диапазоне от 1 - плохо, до 5 - отлично)\n",
    "2. Качесвто еды (оцени в диапазоне от 1 - плохо, до 5 - отлично)\n",
    "3. Общая тональность отзыва: положительный (1) или отрицательный (-1).\n",
    "4. Краткое содержание отзыва в 5-7 словах.\n",
    "5. Перевод краткого отзыва на английский.\n",
    "Результат верни в формате JSON такого вида:\n",
    "{{\n",
    "  \"обслуживание\" : <оценка>,\n",
    "  \"еда\" : <оценка>,\n",
    "  \"тональность\" : <оценка>,\n",
    "  \"саммари\" : \"<краткое содержание>\",\n",
    "  \"англ\" : \"<перевод краткого отзыва на английский>\"\n",
    "}}\n",
    "Вот сам отзыв:\n",
    "```{review}```\n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"review\"],\n",
    ")\n",
    "\n",
    "tab = []\n",
    "GPT.temperature = 0.5\n",
    "for r in reviews:\n",
    "    res = GPT(prompt.format(review=r))\n",
    "    js = parser.parse(res)\n",
    "    print(js)\n",
    "    tab.append(js)\n",
    "    time.sleep(1)\n",
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "\n",
    "parser = SimpleJsonOutputParser()\n",
    "\n",
    "review = \"\"\"\n",
    "* Я был а Макдональдсе четыре раза, и каждый раз это было удивительно! Столько вкусов мороженого я никогда не пробовал! И все официантки за кассой очень молодые и симпатичные!\n",
    "* Бургер кинг - ужасное заведение! Я очень долго ждал, пока заказ приготовится. При этом бургер был жестким, и соус немного отдавал машинным маслом. Никогда больше туда не приду!\n",
    "* Я слышал, что в Макдональдсе котлеты готовят из костей животных, и сегодня я в этом убедился сам! В котлете попалось что-то жесткое, и я чуть не сломал зуб!\n",
    "* Хочу выразить благодарность сотрудникам \"Чебуречная №1\" - мы прекрасно отметили там мой день рождения! Официант Игорь был очень услужлив, и даже зажег свечку, воткнутую в чебурек, чтобы мы могли отметить день рождения! Их квас выше всех похвал!\n",
    "\"\"\"\n",
    "\n",
    "template = '''\n",
    "У меня есть список отзывов из ресторанов (ниже в тройных обратных кавычках). \n",
    "Пожалуйста, сформируй таблицу в формате Markdown,\n",
    "в которой для каждого отзыва напиши:\n",
    "* Название ресторана\n",
    "* Оценку его позитивности или негативности по шкале -5..5\n",
    "* Общую оценку: позитивный он или негативный\n",
    "* Оценка кухни ресторана: от 0 до 5\n",
    "* Оценка обслуживания ресторана: от 0 до 5\n",
    "* Список позитивных моментов\n",
    "* Список негативных моментов\n",
    "Вот список отзывов:\n",
    "```\n",
    "{review}\n",
    "```\n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"review\"],\n",
    ")\n",
    "\n",
    "tab = []\n",
    "GPT.temperature = 0.5\n",
    "for r in reviews:\n",
    "    res = GPT(prompt.format(review=r))\n",
    "    js = parser.parse(res)\n",
    "    print(js)\n",
    "    tab.append(js)\n",
    "    time.sleep(1)\n",
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем перефразировать отзывы. Как думаете, это может быть полезно для SMM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "_MultiThreadedRendezvous",
     "evalue": "<_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.RESOURCE_EXHAUSTED\n\tdetails = \"Error in session internal_id=e3b313d9-32f3b452-7e3374d-79330b29&request_id=45ec1fb7-9e09-4a30-8261-b566382ddd9a&client_request_id=undefined&folder_id=b1gs3gfaglk70c1glk7s: \"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:158.160.54.160:443 {created_time:\"2023-11-09T11:55:58.5326839+00:00\", grpc_status:8, grpc_message:\"Error in session internal_id=e3b313d9-32f3b452-7e3374d-79330b29&request_id=45ec1fb7-9e09-4a30-8261-b566382ddd9a&client_request_id=undefined&folder_id=b1gs3gfaglk70c1glk7s: \"}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_MultiThreadedRendezvous\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32md:\\GIT\\PresentationDemos\\PiterPy2023\\GPT4Dev.ipynb Cell 39\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GIT/PresentationDemos/PiterPy2023/GPT4Dev.ipynb#X53sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m GPT\u001b[39m.\u001b[39mtemperature \u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GIT/PresentationDemos/PiterPy2023/GPT4Dev.ipynb#X53sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m reviews:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/GIT/PresentationDemos/PiterPy2023/GPT4Dev.ipynb#X53sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     res \u001b[39m=\u001b[39m GPT(prompt\u001b[39m.\u001b[39;49mformat(review\u001b[39m=\u001b[39;49mr))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GIT/PresentationDemos/PiterPy2023/GPT4Dev.ipynb#X53sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mprint\u001b[39m(res)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GIT/PresentationDemos/PiterPy2023/GPT4Dev.ipynb#X53sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\winapp\\conda\\envs\\fresh\\lib\\site-packages\\langchain\\chat_models\\base.py:600\u001b[0m, in \u001b[0;36mBaseChatModel.__call__\u001b[1;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[0;32m    594\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    595\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    599\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BaseMessage:\n\u001b[1;32m--> 600\u001b[0m     generation \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate(\n\u001b[0;32m    601\u001b[0m         [messages], stop\u001b[39m=\u001b[39mstop, callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    602\u001b[0m     )\u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[0;32m    603\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(generation, ChatGeneration):\n\u001b[0;32m    604\u001b[0m         \u001b[39mreturn\u001b[39;00m generation\u001b[39m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\winapp\\conda\\envs\\fresh\\lib\\site-packages\\langchain\\chat_models\\base.py:349\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[39mif\u001b[39;00m run_managers:\n\u001b[0;32m    348\u001b[0m             run_managers[i]\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[1;32m--> 349\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    350\u001b[0m flattened_outputs \u001b[39m=\u001b[39m [\n\u001b[0;32m    351\u001b[0m     LLMResult(generations\u001b[39m=\u001b[39m[res\u001b[39m.\u001b[39mgenerations], llm_output\u001b[39m=\u001b[39mres\u001b[39m.\u001b[39mllm_output)\n\u001b[0;32m    352\u001b[0m     \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results\n\u001b[0;32m    353\u001b[0m ]\n\u001b[0;32m    354\u001b[0m llm_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_combine_llm_outputs([res\u001b[39m.\u001b[39mllm_output \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results])\n",
      "File \u001b[1;32mc:\\winapp\\conda\\envs\\fresh\\lib\\site-packages\\langchain\\chat_models\\base.py:339\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[39mfor\u001b[39;00m i, m \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(messages):\n\u001b[0;32m    337\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    338\u001b[0m         results\u001b[39m.\u001b[39mappend(\n\u001b[1;32m--> 339\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    340\u001b[0m                 m,\n\u001b[0;32m    341\u001b[0m                 stop\u001b[39m=\u001b[39mstop,\n\u001b[0;32m    342\u001b[0m                 run_manager\u001b[39m=\u001b[39mrun_managers[i] \u001b[39mif\u001b[39;00m run_managers \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    343\u001b[0m                 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    344\u001b[0m             )\n\u001b[0;32m    345\u001b[0m         )\n\u001b[0;32m    346\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    347\u001b[0m         \u001b[39mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\winapp\\conda\\envs\\fresh\\lib\\site-packages\\langchain\\chat_models\\base.py:492\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    489\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    490\u001b[0m     )\n\u001b[0;32m    491\u001b[0m \u001b[39mif\u001b[39;00m new_arg_supported:\n\u001b[1;32m--> 492\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(\n\u001b[0;32m    493\u001b[0m         messages, stop\u001b[39m=\u001b[39mstop, run_manager\u001b[39m=\u001b[39mrun_manager, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    494\u001b[0m     )\n\u001b[0;32m    495\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(messages, stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\winapp\\conda\\envs\\fresh\\lib\\site-packages\\langchain\\chat_models\\yandex.py:117\u001b[0m, in \u001b[0;36mChatYandexGPT._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m     metadata \u001b[39m=\u001b[39m ((\u001b[39m\"\u001b[39m\u001b[39mauthorization\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mApi-Key \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m),)\n\u001b[0;32m    116\u001b[0m res \u001b[39m=\u001b[39m stub\u001b[39m.\u001b[39mChat(request, metadata\u001b[39m=\u001b[39mmetadata)\n\u001b[1;32m--> 117\u001b[0m text \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(res)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mtext\n\u001b[0;32m    118\u001b[0m text \u001b[39m=\u001b[39m text \u001b[39mif\u001b[39;00m stop \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m enforce_stop_tokens(text, stop)\n\u001b[0;32m    119\u001b[0m message \u001b[39m=\u001b[39m AIMessage(content\u001b[39m=\u001b[39mtext)\n",
      "File \u001b[1;32mc:\\winapp\\conda\\envs\\fresh\\lib\\site-packages\\grpc\\_channel.py:541\u001b[0m, in \u001b[0;36m_Rendezvous.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 541\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next()\n",
      "File \u001b[1;32mc:\\winapp\\conda\\envs\\fresh\\lib\\site-packages\\grpc\\_channel.py:967\u001b[0m, in \u001b[0;36m_MultiThreadedRendezvous._next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    965\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m()\n\u001b[0;32m    966\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state\u001b[39m.\u001b[39mcode \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 967\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "\u001b[1;31m_MultiThreadedRendezvous\u001b[0m: <_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.RESOURCE_EXHAUSTED\n\tdetails = \"Error in session internal_id=e3b313d9-32f3b452-7e3374d-79330b29&request_id=45ec1fb7-9e09-4a30-8261-b566382ddd9a&client_request_id=undefined&folder_id=b1gs3gfaglk70c1glk7s: \"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:158.160.54.160:443 {created_time:\"2023-11-09T11:55:58.5326839+00:00\", grpc_status:8, grpc_message:\"Error in session internal_id=e3b313d9-32f3b452-7e3374d-79330b29&request_id=45ec1fb7-9e09-4a30-8261-b566382ddd9a&client_request_id=undefined&folder_id=b1gs3gfaglk70c1glk7s: \"}\"\n>"
     ]
    }
   ],
   "source": [
    "template = '''\n",
    "Ниже в тройных обратных кавычках приводится отзыв посетитея о ресторане. Пожалуйста,\n",
    "перепиши этот отзыв литературным языком в стиле Льва Толстого:\n",
    "```{review}```\n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"review\"],\n",
    ")\n",
    "\n",
    "GPT.temperature = 0.5\n",
    "for r in reviews:\n",
    "    res = GPT(prompt.format(review=r))\n",
    "    print(res)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кстати, на отзывы можно сразу же ответить! Это сократит работу отделу маркетинга!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Я посетил ресторан Макдональдс летом прошлого года, и был разочарован!\n",
      "Из позитивных моментов: обслуживание было быстрым, я получил заказ через 5 минут.\n",
      "Но при этом весь персонал был мрачным, и еда оказалась не очень вкусной. Картошка\n",
      "была сырая и пахла резиной, а мясо в гамбургере было серым на цвет.\n",
      "\n",
      "Уважаемый гость!\n",
      "\n",
      "Благодарим Вас за оставленный отзыв. Нам искренне жаль, что посещение нашего ресторана оставило у Вас столь негативное впечатление. Мы обязательно обратим внимание на указанные Вами моменты и проведем работу над их устранением.\n",
      "\n",
      "Что касается обслуживания, то мы стараемся как можно скорее принимать и обслуживать гостей. Надеемся, что в следующий раз Вы получите еще более быстрое обслуживание.\n",
      "\n",
      "Относительно качества блюд, хотелось бы отметить, что у нас действует жесткий контроль качества и свежести продуктов. Приношу Вам свои извинения за то, что картошка была сырой, возможно, это была случайность. Мы всегда готовы заменить блюдо.\n",
      "\n",
      "Еще раз благодарим Вас за обратную связь. Будем рады видеть Вас снова и постараемся сделать все возможное, чтобы Ваше следующее посещение нашего ресторана было максимально комфортным и приятным.\n",
      "-----------\n",
      "\n",
      "Макдональдс - это прекрасное место, где можно поесть американскую еду:\n",
      "гамбургеры, картошку фри и конечно же прекрасное мороженое!\n",
      "Я обычно заказываю биг мак, в котором много вкусного зелёного салата.\n",
      "Это делает еду полезной и здоровой, что очень хорошо! Спасибо всем официантам,\n",
      "которые всегда улыбаются и радуются мне!\n",
      "\n",
      "Здравствуйте!\n",
      "\n",
      "Благодарим вас за такой приятный отзыв. Мы рады, что вам нравится наша еда и обслуживание. Будем стараться и дальше радовать вас вкусной и качественной едой. Приходите к нам ещё!\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "template = '''\n",
    "Ниже в тройных обратных кавычках приводится отзыв посетитея о ресторане. Пожалуйста,\n",
    "напиши ответ на этот отзыв от лица представителя ресторана. Если отзыв отрицательный, то\n",
    "принеси свои извинения. В случае положительного отзыва, поблагодари.\n",
    "Вот отзыв:\n",
    "```{review}```\n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"review\"],\n",
    ")\n",
    "\n",
    "GPT.temperature = 0.5\n",
    "for r in reviews:\n",
    "    res = GPT(prompt.format(review=r))\n",
    "    print(r)\n",
    "    print(res)\n",
    "    print('-----------')\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"модель\": \"iPhone 15\",\n",
      "  \"тональность\": \"положительная\",\n",
      "  \"минусы\": [\"доставка\"],\n",
      "  \"плюсы\": [\"приятная цена\", \"качество камеры\"]\n",
      "}\n",
      "{\n",
      "  \"модель\": \"Poco X1\",\n",
      "  \"тональность\": \"отрицательная\",\n",
      "  \"минусы\": [\"некрасивая упаковка\", \"матовый экран\", \"тусклый экран\", \"замыленные фотографии\"],\n",
      "  \"плюсы\": []\n",
      "}\n",
      "{\n",
      "  \"модель\": \"Samsung Galaxy\",\n",
      "  \"тональность\": \"положительная\",\n",
      "  \"минусы\": [],\n",
      "  \"плюсы\": [\"отличная камера\", \"быстродействие\", \"дизайн\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "feedback = [\n",
    "    'Купил iPhone 15. Ну что сказать - очень доволен покупкой! Приятный цвет, телефон просто летает, да и камера достаточно хороша!',\n",
    "    'Заказанный телефон Poco X1 пришел в некрасивой упаковке. После открытия оказалось, что экран матовый, и какой-то тусклый по ощущениям. Все фотографии получаются замыленные. В общем, никому не рекомендую покупку!',\n",
    "    'Отличная быстрая доставка! Наслаждаюсь своим новеньким Samsung Galaxy!'\n",
    "]\n",
    "\n",
    "prompt = '''\n",
    "Посмотри на отзыв покупателя магазина сотовых телефонов, и извлеки из него следующую информацию:\n",
    "1. Название модели телефона\n",
    "2. Тональность отзывы: положительная, отрицательная или нейтральная.\n",
    "3. Основные минусы в отзыве (доставка, камера, внешний вид и др.)\n",
    "4. Основные плюсы в отзыве\n",
    "Представь результат в формате JSON такого вида:\n",
    "{\n",
    "  \"модель\" : ...,\n",
    "  \"тональность\" : ...,\n",
    "  \"минусы\" : [...],\n",
    "  \"плюсы\" : [...]\n",
    "}\n",
    "Ниже сам текст отзыва:\n",
    "'''\n",
    "\n",
    "for x in feedback:\n",
    "    res = GPT(prompt+x)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
